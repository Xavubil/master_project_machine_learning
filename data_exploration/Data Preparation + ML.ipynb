{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime\n",
    "import statistics as stats\n",
    "import tsfresh.feature_extraction.feature_calculators as fc\n",
    "from functools import reduce\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Daten einlesen und Spalten entfernen welche nicht benötigt werden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reib_daten = pd.read_csv('data_2019-26-11_TRAININGDATA.csv')\n",
    "achsleistung_daten = pd.read_csv('../Achsleistungen _ Messprotokolle/Ebene 1/Achsleistung-2019-11-20T10-27-03.csv', \\\n",
    "                                 delimiter=';')\n",
    "messprotokoll_daten = pd.read_csv('../Achsleistungen _ Messprotokolle/Ebene 1/MEAS_PROTOCOL_CSV.CSV', delimiter=';')\n",
    "messergebnisse_daten = pd.read_csv('../Messergebnisse Reiben/Messergebnisse.csv', skiprows=7, delimiter=';')\n",
    "achsleistung_columns = ['Timestamp', 'X1', 'Y1', 'Z1', 'SPI1']\n",
    "messergebnisse_columns = ['Messwert Innenmessschraube', 'Messwert Messtaster', 'Klassifizierung nach Messtaster', \\\n",
    "                          'Klassifizierung nach Messtaster', 'Klassifizierung nach Grenzlehrdorn']\n",
    "achsleistung_daten = achsleistung_daten[achsleistung_columns]\n",
    "messergebnisse_daten = messergebnisse_daten[messergebnisse_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anpassen und aufbereiten Messprotokolldaten\n",
    "Da die Maschine die Werte in der Exceltabelle sehr schlecht formatiert - viele Tabulatoren und alle Zahlen sind strings. Zusätzlich werden noch alle null values entfernt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "messprotokoll_daten = messprotokoll_daten.rename(columns=lambda x: x.strip())\n",
    "messprotokoll_columns = ['Measured', 'Difference']\n",
    "messprotokoll_daten = messprotokoll_daten[messprotokoll_columns]\n",
    "\n",
    "for column, value in enumerate(messprotokoll_columns):\n",
    "    messprotokoll_daten[value] = messprotokoll_daten[value].str.strip()\n",
    "    messprotokoll_daten[value] = messprotokoll_daten[value].str.replace(',', '.')\n",
    "    messprotokoll_daten[value] = messprotokoll_daten[value].apply(pd.to_numeric, errors='coerce')\n",
    "\n",
    "print(messprotokoll_daten.dtypes)\n",
    "\n",
    "achsleistung_daten = achsleistung_daten.dropna()\n",
    "messprotokoll_daten = messprotokoll_daten.dropna()\n",
    "messergebnisse_daten = messergebnisse_daten.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Berechnung Mittelwert und Median für Messprotokolldaten\n",
    "\n",
    "Hier werden die Daten für das Messprotokoll angepasst. Da hier eine Bohrung aus drei Werten besteht (Spalte Result: X, Y, Diameter), werden alle drei Werte genommen und aggregiert $\\rightarrow$ Median + Mittelwert.\n",
    "\n",
    "Danach wird das Messprotokoll mit den Daten der Messergebnisse gemerged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filling_columns = ['Measured Mean', 'Measured Median', 'Difference Mean', 'Difference Median']\n",
    "\n",
    "messprotokoll_condensed = pd.DataFrame(columns=filling_columns)\n",
    "measured_avg = []\n",
    "measured_median = []\n",
    "diameter_avg = []\n",
    "diameter_median = []\n",
    "count = 1\n",
    "for key, value in messprotokoll_daten.iteritems():\n",
    "    if key == 'Measured':\n",
    "        meas = []\n",
    "        for index, floating in enumerate(value):\n",
    "            meas.append(floating)\n",
    "            if (count % 3) == 0:\n",
    "                mean_meas = stats.mean(meas)\n",
    "                median_meas = stats.median(meas)\n",
    "                measured_avg.append(mean_meas)\n",
    "                measured_median.append(median_meas)\n",
    "                #print(measured_avg, '\\n', measured_median)\n",
    "                del meas[:]\n",
    "                \n",
    "            #print(count % 3 == 0, meas, count)\n",
    "            if count == 1:\n",
    "                pass\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "    elif key == 'Difference':\n",
    "        diff = []\n",
    "        for index, floating in enumerate(value):\n",
    "            diff.append(abs(floating))\n",
    "            if (count % 3) == 0:\n",
    "                mean_diff = np.mean(diff)\n",
    "                median_diff = np.median(diff)\n",
    "                diameter_avg.append(mean_diff)\n",
    "                diameter_median.append(median_diff)\n",
    "                del diff[:]\n",
    "            \n",
    "            if count == 1:\n",
    "                pass\n",
    "            \n",
    "            count += 1\n",
    "\n",
    "            \n",
    "\n",
    "messprotokoll_condensed['Measured Mean'] = measured_avg\n",
    "messprotokoll_condensed['Measured Median'] = measured_median\n",
    "messprotokoll_condensed['Difference Mean'] = diameter_avg\n",
    "messprotokoll_condensed['Difference Median'] = diameter_median\n",
    "\n",
    "merge_csv_erg_prot = messergebnisse_daten[:81].merge(messprotokoll_condensed, right_index=True , left_index=True)\n",
    "\n",
    "merge_csv_erg_prot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Achsleitungsverarbeitung und entfernung Ausreiser?\n",
    "Hier wird die Achleistung bearbeitet. Diskutierbar ist, ob \"Ausreiser\" die durch Median * 3 ermittelt werden, entfernt werden müssen oder nicht. Es macht keine Unterschiede in der Anzahl der Daten, jedoch in deren Aggregierten Werten (Max, Mean, Median)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete any row with 0's in SPI\n",
    "achsleistung_daten = achsleistung_daten[(achsleistung_daten[['SPI1']] != 0).all(axis=1)]\n",
    "\n",
    "# remove median > 3 for all columns\n",
    "for key, value in achsleistung_daten.items():\n",
    "    if achsleistung_daten[key].dtypes == 'float64':\n",
    "        achsleistung_daten.drop(achsleistung_daten[value > (3 * stats.mean(achsleistung_daten[key]))].index, inplace=True)\n",
    "        \n",
    "\n",
    "achsleistung_daten = achsleistung_daten.set_index(['Timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# achsleistung_daten.index = pd.to_datetime(achsleistung_daten.index)\n",
    "# print(achsleistung_daten.index[-1], achsleistung_daten.index[0])\n",
    "# time_diff = (achsleistung_daten.index[-1] - achsleistung_daten.index[0])\n",
    "\n",
    "# resampling_range = time_diff.total_seconds() / 81\n",
    "\n",
    "# print(math.floor(resampling_range))\n",
    "\n",
    "# index_series = pd.date_range(start=achsleistung_daten.index[0], end=achsleistung_daten.index[-1], periods=time_diff.total_seconds())\n",
    "\n",
    "# achsleistung_daten = achsleistung_daten.reindex(achsleistung_daten.index.union(index_series)).interpolate(method='time').reindex(index_series)\n",
    "\n",
    "# achsleistung_daten\n",
    "#dateRangeAndAggregate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aufteilung der Daten in gleich große Zeitintervalle und Aggregierung der Daten\n",
    "Hier wird zunächst die Gesamtzeit zwischen Start und Ende der Achsleistung bestimmt. Diese wird durch 81 geteilt (um einen Zeitraum für eine Bohrung bestimmen zu können), und mit diesem Zeitraum werden die Daten auf verschiedenen Aggregationen - Max, Min, Mean, Median - neu gesampled.\n",
    "Die berechneten Werte werden dann dem zuvor erstellten DataFrame \"merge_csv_erg_prot\" hinzugefügt.\n",
    "\n",
    "Die Datenverarbeitung ist damit abgeschlossen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_df(dataframe):\n",
    "    reduced_frame = reduce(lambda left,right: pd.merge(left,right,on='Timestamp'), dataframe)\n",
    "    return reduced_frame\n",
    "\n",
    "achsleistung_daten.index = pd.to_datetime(achsleistung_daten.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_diff = (achsleistung_daten.index[-1] - achsleistung_daten.index[0])\n",
    "resampling_range = (time_diff.total_seconds() / 81)\n",
    "\n",
    "print('resampling range: '+ str(resampling_range) + '\\ntime difference: ' + str(time_diff) + \\\n",
    "      '\\ntime of one drill: ' + str((time_diff / resampling_range)))\n",
    "\n",
    "sampled_mean = achsleistung_daten.resample(str(math.ceil(resampling_range))+'S').mean()\n",
    "sampled_median = achsleistung_daten.resample(str(math.ceil(resampling_range))+'S').median()\n",
    "sampled_max = achsleistung_daten.resample(str(math.ceil(resampling_range))+'S').max()\n",
    "sampled_min = achsleistung_daten.resample(str(math.ceil(resampling_range))+'S').min()\n",
    "#sampled_app_entropy = achsleistung_daten.resample(str(math.ceil(resampling_range))+'S').apply(fc.approximate_entropy(achsleistung_daten), 81, r=1.0)\n",
    "#sampled_std_deviation = fc.standard_deviation(achsleistung_daten.resample(str(math.ceil(resampling_range))+'S').std())\n",
    "\n",
    "sampled_mean = sampled_mean.rename(\n",
    "    columns={'X1': 'X1_mean', 'Y1': 'Y1_mean', 'Z1': 'Z1_mean', 'SPI1': 'SPI1_mean'})\n",
    "sampled_median = sampled_median.rename(\n",
    "    columns={'X1': 'X1_median', 'Y1': 'Y1_median', 'Z1': 'Z1_median', 'SPI1': 'SPI1_median'})\n",
    "sampled_max = sampled_max.rename(                         \n",
    "    columns={'X1': 'X1_max', 'Y1': 'Y1_max', 'Z1': 'Z1_max', 'SPI1': 'SPI1_max'})\n",
    "sampled_min = sampled_min.rename(                         \n",
    "    columns={'X1': 'X1_min', 'Y1': 'Y1_min', 'Z1': 'Z1_min', 'SPI1': 'SPI1_min'})\n",
    "        \n",
    "        \n",
    "df_list = [sampled_mean, sampled_median, sampled_max, sampled_min]\n",
    "df_final = reduce_df(df_list)\n",
    "\n",
    "df_final = df_final.reset_index()\n",
    "\n",
    "df_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_csv_erg_prot = merge_csv_erg_prot.merge(df_final, right_index=True, left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_csv_erg_prot"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
